# Test Plan: list_vulnerability_types MCP Tool

## Overview

This test plan provides comprehensive instructions for testing the `list_vulnerability_types` MCP tool in the mcp-contrast server. This tool returns a complete list of all vulnerability types (rule names) available in a Contrast organization.

**Tool Location**: `/Users/chrisedwards/projects/contrast/mcp-contrast/src/main/java/com/contrast/labs/ai/mcp/contrast/AssessService.java` (lines 598-639)

**Tool Purpose**: Returns the complete list of vulnerability types (rule names) available in Contrast, which can be used to discover all possible values for the `vulnTypes` filter parameter when calling `list_all_vulnerabilities` or other vulnerability filtering tools.

## Prerequisites

1. MCP server must be running with valid Contrast credentials
2. Access to a Contrast organization with configured rules
3. MCP client capable of invoking tools (e.g., Claude Desktop, Claude Code, or custom MCP client)

## Test Data Requirements

For comprehensive testing, you will need access to:

1. **Standard Organization**: An organization with common vulnerability rules configured (sql-injection, xss-reflected, path-traversal, cmd-injection, etc.)
2. **Empty/New Organization**: An organization with no rules configured (optional, for negative testing)
3. **Large Organization**: An organization with many rules (50+ rules) to test performance and sorting

## Test Cases

### Test Case 1: Basic Functionality - Retrieve All Vulnerability Types

**Objective**: Verify the tool successfully retrieves and returns vulnerability type names.

**Test Data Needed**: Standard Contrast organization with rules configured.

**Test Steps**:
1. Invoke the `list_vulnerability_types` tool via MCP
2. Observe the response

**Expected Results**:
- Tool returns successfully without errors
- Response is a list/array of strings
- List contains at least one vulnerability type
- Each item in the list is a non-empty string

**Verification**:
```
✓ Response status: Success
✓ Response type: Array/List
✓ Response length: > 0
✓ All items are non-empty strings
```

**Sample Expected Output**:
```json
[
  "cmd-injection",
  "crypto-bad-mac",
  "path-traversal",
  "sql-injection",
  "xss-reflected"
]
```

---

### Test Case 2: Data Completeness - Common Vulnerability Types Present

**Objective**: Verify that common OWASP vulnerability types are present in the results.

**Test Data Needed**: Organization with standard Contrast rules enabled (most production organizations).

**Test Steps**:
1. Invoke the `list_vulnerability_types` tool
2. Examine the returned list for common vulnerability types

**Expected Results**:
The returned list should include common vulnerability types such as:
- `sql-injection` or SQL injection related rules
- `xss-reflected` or `xss-stored` (cross-site scripting)
- `path-traversal` or directory traversal rules
- `cmd-injection` or command injection rules
- `crypto-*` rules (cryptography-related)
- `xxe` (XML external entity)
- `ldap-injection`
- `nosql-injection`

**Verification**:
```
✓ At least 5 common vulnerability types present
✓ XSS-related rules present (xss-*)
✓ Injection-related rules present (*-injection)
✓ Cryptography rules present (crypto-*)
```

**Note**: The exact rule names depend on your Contrast organization configuration. Adjust expectations based on your organization's enabled rules.

---

### Test Case 3: Alphabetical Sorting

**Objective**: Verify that vulnerability types are returned in alphabetical order.

**Test Data Needed**: Organization with at least 5 rules configured.

**Test Steps**:
1. Invoke the `list_vulnerability_types` tool
2. Capture the complete returned list
3. Verify the sorting order

**Expected Results**:
- Results are sorted alphabetically (case-sensitive, ascending order)
- For example: `["cmd-injection", "crypto-bad-mac", "path-traversal", "sql-injection", "xss-reflected"]`

**Verification**:
```
✓ Each item is lexicographically less than or equal to the next item
✓ First item starts with an early letter (a-c typically)
✓ Last item starts with a later letter (t-z typically)
```

**Verification Logic**:
For each pair of adjacent items (item[i], item[i+1]):
- item[i].compareTo(item[i+1]) <= 0

---

### Test Case 4: Data Format - Names are Trimmed and Non-Empty

**Objective**: Verify that all returned rule names are properly formatted (trimmed, no leading/trailing whitespace, non-empty).

**Test Data Needed**: Any organization with rules configured.

**Test Steps**:
1. Invoke the `list_vulnerability_types` tool
2. Examine each item in the returned list

**Expected Results**:
- No empty strings in the list
- No null values in the list
- No leading whitespace on any rule name
- No trailing whitespace on any rule name
- All rule names follow the pattern: lowercase letters, numbers, and hyphens

**Verification**:
```
✓ No empty strings: all items have length > 0
✓ No null values: all items are defined
✓ No whitespace: item.trim() === item for all items
✓ Format pattern: each item matches /^[a-z0-9-]+$/
```

**Sample Verification Code Pattern**:
```javascript
results.forEach(ruleName => {
  assert(ruleName !== null, "Rule name should not be null");
  assert(ruleName.length > 0, "Rule name should not be empty");
  assert(ruleName === ruleName.trim(), "Rule name should be trimmed");
  assert(/^[a-z0-9-]+$/.test(ruleName), "Rule name should match pattern");
});
```

---

### Test Case 5: Empty Results - Organization with No Rules

**Objective**: Verify graceful handling when an organization has no rules configured.

**Test Data Needed**: Empty/new Contrast organization with no rules configured (or mock this scenario).

**Test Steps**:
1. Configure access to an organization with no rules
2. Invoke the `list_vulnerability_types` tool
3. Observe the response

**Expected Results**:
- Tool returns successfully (no error)
- Response is an empty list/array `[]`
- No null response
- No error message

**Verification**:
```
✓ Response status: Success (not error)
✓ Response type: Array/List
✓ Response length: 0
✓ Response is [] not null
```

**Note**: If you cannot access an organization with no rules, this test case can be marked as "Not Applicable" or simulated via unit tests.

---

### Test Case 6: Large Data Set - Performance and Sorting

**Objective**: Verify the tool performs well with large numbers of rules and maintains proper sorting.

**Test Data Needed**: Organization with 50+ rules configured.

**Test Steps**:
1. Invoke the `list_vulnerability_types` tool on an organization with many rules
2. Measure response time
3. Verify sorting on the complete list

**Expected Results**:
- Tool completes within reasonable time (< 5 seconds)
- All rules are returned
- Complete list is sorted alphabetically
- No duplicate entries

**Verification**:
```
✓ Response time: < 5 seconds
✓ Response length: >= 50
✓ All items are sorted: verified by comparing adjacent pairs
✓ No duplicates: Set(results).size === results.length
✓ All items are unique
```

---

### Test Case 7: Integration - Using Results with list_all_vulnerabilities

**Objective**: Verify that the rule names returned can be successfully used as filter values in other tools.

**Test Data Needed**: Organization with vulnerabilities present.

**Test Steps**:
1. Invoke `list_vulnerability_types` and capture results
2. Select 1-2 rule names from the results (e.g., "sql-injection")
3. Invoke `list_all_vulnerabilities` with vulnTypes filter using the selected rule names
4. Verify the filtered results

**Expected Results**:
- `list_all_vulnerabilities` accepts the rule names without error
- Returned vulnerabilities match the specified rule types
- No "invalid rule type" errors

**Verification**:
```
✓ list_all_vulnerabilities call succeeds
✓ Filtered results contain only the specified vulnerability types
✓ All returned vulnerabilities have rule field matching the filter
```

**Example Flow**:
```
1. types = list_vulnerability_types()
   → ["cmd-injection", "sql-injection", "xss-reflected"]

2. vulns = list_all_vulnerabilities(vulnTypes="sql-injection,xss-reflected")
   → All returned vulnerabilities have rule in ["sql-injection", "xss-reflected"]
```

---

### Test Case 8: Error Handling - API Connection Failure

**Objective**: Verify proper error handling when the Contrast API is unavailable.

**Test Data Needed**: Simulated API failure (invalid credentials, network issue, or stopped TeamServer).

**Test Steps**:
1. Configure MCP server with invalid credentials OR disconnect from network
2. Invoke `list_vulnerability_types`
3. Observe error response

**Expected Results**:
- Tool returns an error (not success)
- Error message indicates connection/API failure
- Error message contains helpful information: "Failed to retrieve vulnerability types"
- No crash or hang

**Verification**:
```
✓ Response indicates error/failure
✓ Error message contains "Failed to retrieve vulnerability types"
✓ Tool does not hang indefinitely
✓ Error is user-friendly (not raw stack trace)
```

**Note**: This test may require special setup or may be performed via unit tests with mocked SDK.

---

## Test Execution Summary Template

Use this template to record test execution results:

| Test Case | Status | Notes | Date Tested |
|-----------|--------|-------|-------------|
| TC1: Basic Functionality | ☐ Pass ☐ Fail | | |
| TC2: Data Completeness | ☐ Pass ☐ Fail | | |
| TC3: Alphabetical Sorting | ☐ Pass ☐ Fail | | |
| TC4: Data Format | ☐ Pass ☐ Fail | | |
| TC5: Empty Results | ☐ Pass ☐ Fail ☐ N/A | | |
| TC6: Large Data Set | ☐ Pass ☐ Fail ☐ N/A | | |
| TC7: Integration Test | ☐ Pass ☐ Fail | | |
| TC8: Error Handling | ☐ Pass ☐ Fail ☐ N/A | | |

---

## Additional Verification Points

### Response Schema Validation

The tool should return a JSON array of strings:
```json
[
  "string",
  "string",
  ...
]
```

### Performance Benchmarks

- Small organization (1-10 rules): < 1 second
- Medium organization (11-50 rules): < 2 seconds
- Large organization (50+ rules): < 5 seconds

### Logging Verification

Check the MCP server logs (`/tmp/mcp-contrast.log`) for:
- Info log: "Retrieving all vulnerability types (rule names) for organization: {orgId}"
- Info log: "Retrieved {count} vulnerability types"
- No error or warning logs (in successful case)

---

## Known Limitations and Notes

1. **Organization-Specific**: The returned list depends on which rules are configured for your specific Contrast organization. Different organizations may have different rule sets.

2. **Dynamic List**: The list is fetched dynamically from Contrast and reflects current configuration, not a static list.

3. **Case Sensitivity**: Rule names are case-sensitive and typically lowercase with hyphens (kebab-case).

4. **No Pagination**: This tool returns all rules in a single response (no pagination needed as rule lists are typically small).

5. **Duplicate Handling**: The implementation filters duplicates during processing, so the returned list should never contain duplicates.

---

## Troubleshooting

### Issue: Empty list returned but organization has rules
**Possible Causes**:
- Incorrect organization ID configured
- API credentials lack permission to view rules
- Contrast SDK version incompatibility

**Resolution**:
- Verify orgID in MCP server configuration
- Check API key permissions in Contrast UI
- Review server logs for detailed error messages

### Issue: Results not sorted alphabetically
**Possible Causes**:
- Bug in implementation
- Locale-specific sorting differences

**Resolution**:
- File a bug report with specific examples
- Check if locale settings affect string comparison

### Issue: Tool returns error "Failed to retrieve vulnerability types"
**Possible Causes**:
- Network connectivity issue
- Invalid Contrast API credentials
- Contrast TeamServer unavailable

**Resolution**:
- Verify network connectivity to Contrast host
- Test credentials with Contrast API directly
- Check Contrast TeamServer status

---

## Success Criteria

The `list_vulnerability_types` tool is considered fully functional when:

1. ✓ Basic functionality test passes (TC1)
2. ✓ Results are alphabetically sorted (TC3)
3. ✓ All rule names are properly formatted (TC4)
4. ✓ Integration with other tools works (TC7)
5. ✓ Error handling is graceful (TC8)
6. ✓ No crashes or hangs observed
7. ✓ Performance is acceptable (< 5 seconds for large datasets)

---

## References

- **Tool Implementation**: `/Users/chrisedwards/projects/contrast/mcp-contrast/src/main/java/com/contrast/labs/ai/mcp/contrast/AssessService.java` (lines 598-639)
- **Unit Tests**: `/Users/chrisedwards/projects/contrast/mcp-contrast/src/test/java/com/contrast/labs/ai/mcp/contrast/AssessServiceTest.java` (lines 248-442)
- **Related Tool**: `list_all_vulnerabilities` (uses vulnerability types as filter parameter)
- **Contrast SDK**: `ContrastSDK.getRules(orgID)` method
